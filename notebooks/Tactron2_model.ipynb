{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_chars,\n",
    "                 num_speakers,\n",
    "                 r,\n",
    "                 postnet_output_dim=80,\n",
    "                 decoder_output_dim=80,\n",
    "                 attn_type='original',\n",
    "                 attn_win=False,\n",
    "                 attn_norm=\"softmax\",\n",
    "                 prenet_type=\"original\",\n",
    "                 prenet_dropout=True,\n",
    "                 forward_attn=False,\n",
    "                 trans_agent=False,\n",
    "                 forward_attn_mask=False,\n",
    "                 location_attn=True,\n",
    "                 attn_K=5,\n",
    "                 separate_stopnet=True,\n",
    "                 bidirectional_decoder=False):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.postnet_output_dim = postnet_output_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "        self.n_frames_per_step = r\n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "        decoder_dim = 512 if num_speakers > 1 else 512\n",
    "        encoder_dim = 512 if num_speakers > 1 else 512\n",
    "        proj_speaker_dim = 80 if num_speakers > 1 else 0\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(num_chars, 512, padding_idx=0)\n",
    "        std = sqrt(2.0 / (num_chars + 512))\n",
    "        val = sqrt(3.0) * std  # uniform bounds for std\n",
    "        self.embedding.weight.data.uniform_(-val, val)\n",
    "        if num_speakers > 1:\n",
    "            self.speaker_embedding = nn.Embedding(num_speakers, 512)\n",
    "            self.speaker_embedding.weight.data.normal_(0, 0.3)\n",
    "            self.speaker_embeddings = None\n",
    "            self.speaker_embeddings_projected = None\n",
    "        self.encoder = Encoder(encoder_dim)\n",
    "        self.decoder = Decoder(decoder_dim, self.decoder_output_dim, r, attn_type, attn_win,\n",
    "                               attn_norm, prenet_type, prenet_dropout,\n",
    "                               forward_attn, trans_agent, forward_attn_mask,\n",
    "                               location_attn, attn_K, separate_stopnet, proj_speaker_dim)\n",
    "        if self.bidirectional_decoder:\n",
    "            self.decoder_backward = copy.deepcopy(self.decoder)\n",
    "        self.postnet = Postnet(self.postnet_output_dim)\n",
    "\n",
    "    def _init_states(self):\n",
    "        self.speaker_embeddings = None\n",
    "        self.speaker_embeddings_projected = None\n",
    "\n",
    "    @staticmethod\n",
    "    def shape_outputs(mel_outputs, mel_outputs_postnet, alignments):\n",
    "        mel_outputs = mel_outputs.transpose(1, 2)\n",
    "        mel_outputs_postnet = mel_outputs_postnet.transpose(1, 2)\n",
    "        return mel_outputs, mel_outputs_postnet, alignments\n",
    "\n",
    "    def forward(self, text, text_lengths, mel_specs=None, speaker_ids=None):\n",
    "        self._init_states()\n",
    "        # compute mask for padding\n",
    "        mask = sequence_mask(text_lengths).to(text.device)\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        encoder_outputs = self.encoder(embedded_inputs, text_lengths)\n",
    "        encoder_outputs = self._add_speaker_embedding(encoder_outputs,\n",
    "                                                      speaker_ids)\n",
    "        decoder_outputs, alignments, stop_tokens = self.decoder(\n",
    "            encoder_outputs, mel_specs, mask)\n",
    "        postnet_outputs = self.postnet(decoder_outputs)\n",
    "        postnet_outputs = decoder_outputs + postnet_outputs\n",
    "        decoder_outputs, postnet_outputs, alignments = self.shape_outputs(\n",
    "            decoder_outputs, postnet_outputs, alignments)\n",
    "        if self.bidirectional_decoder:\n",
    "            decoder_outputs_backward, alignments_backward = self._backward_inference(mel_specs, encoder_outputs, mask)\n",
    "            return decoder_outputs, postnet_outputs, alignments, stop_tokens, decoder_outputs_backward, alignments_backward\n",
    "        return decoder_outputs, postnet_outputs, alignments, stop_tokens\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(self, text, speaker_ids=None):\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        encoder_outputs = self.encoder.inference(embedded_inputs)\n",
    "        encoder_outputs = self._add_speaker_embedding(encoder_outputs,\n",
    "                                                      speaker_ids)\n",
    "        mel_outputs, alignments, stop_tokens = self.decoder.inference(\n",
    "            encoder_outputs)\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "        mel_outputs, mel_outputs_postnet, alignments = self.shape_outputs(\n",
    "            mel_outputs, mel_outputs_postnet, alignments)\n",
    "        return mel_outputs, mel_outputs_postnet, alignments, stop_tokens\n",
    "\n",
    "    def inference_truncated(self, text, speaker_ids=None):\n",
    "        \"\"\"\n",
    "        Preserve model states for continuous inference\n",
    "        \"\"\"\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        encoder_outputs = self.encoder.inference_truncated(embedded_inputs)\n",
    "        encoder_outputs = self._add_speaker_embedding(encoder_outputs,\n",
    "                                                      speaker_ids)\n",
    "        mel_outputs, alignments, stop_tokens = self.decoder.inference_truncated(\n",
    "            encoder_outputs)\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "        mel_outputs, mel_outputs_postnet, alignments = self.shape_outputs(\n",
    "            mel_outputs, mel_outputs_postnet, alignments)\n",
    "        return mel_outputs, mel_outputs_postnet, alignments, stop_tokens\n",
    "\n",
    "    def _backward_inference(self, mel_specs, encoder_outputs, mask):\n",
    "        decoder_outputs_b, alignments_b, _ = self.decoder_backward(\n",
    "            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask,\n",
    "            self.speaker_embeddings_projected)\n",
    "        decoder_outputs_b = decoder_outputs_b.transpose(1, 2)\n",
    "        return decoder_outputs_b, alignments_b\n",
    "\n",
    "    def _add_speaker_embedding(self, encoder_outputs, speaker_ids):\n",
    "        if hasattr(self, \"speaker_embedding\") and speaker_ids is None:\n",
    "            raise RuntimeError(\" [!] Model has speaker embedding layer but speaker_id is not provided\")\n",
    "        if hasattr(self, \"speaker_embedding\") and speaker_ids is not None:\n",
    "            speaker_embeddings = self.speaker_embedding(speaker_ids)\n",
    "\n",
    "            speaker_embeddings.unsqueeze_(1)\n",
    "            speaker_embeddings = speaker_embeddings.expand(encoder_outputs.size(0),\n",
    "                                                           encoder_outputs.size(1),\n",
    "                                                           -1)\n",
    "            encoder_outputs = encoder_outputs + speaker_embeddings\n",
    "        return encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
